\documentclass[UTF8]{csoarticle}


\newtheorem{theorem}{定理}
\newtheorem{lemma}{引理}
\renewcommand{\proofname}{证明}
% 如果为英文文章，可以使用下面的定义(去除行首的注释符号%)代替上述中文定义
% \newtheorem{theorem}{Theorem}
% \newtheorem{lemma}{Lemma}

\begin{document}

%----------------------------------------------------------
% 1. 文章标头信息
%----------------------------------------------------------

\titleCHN{基于层次注意力机制的\\远程监督关系抽取算法研究}
\authorCHN{陈元昆\affil{}}
\affiliationCHN{
    \affil{} 北京邮电大学网络空间安全学院，北京　100010
}

\abstractCHN{
远程监督机制由于其使用机器自动标注数据，减少了大量标注人力的优点，逐渐成为了知识图谱构建中关系抽取任务的主要手段。然而，机器自动标注的样本实例，包含了大量的噪声信息，导致了很多基于远程监督数据训练的模型的效果并不理想。
为了解决这个问题，本文提出了一个新型的网络结构，称之为层次注意力机制。
该网络结构将注意力机制组织为层次结构，以更好地应对数据噪声，捕获句子的特征，句袋(sentence bag)特征。
使用自注意力机制作为这两个层次特征的主要的编码器，构建了一个抗噪能力较强的远程监督机制的关系抽取器。
实验表明，该模型在性能方面超过了现有的许多模型。
}
\keywordCHN{深度学习\ 自然语言处理 \ 知识图谱 \ 关系抽取\ 注意力机制\ 远程监督}


\maketitle


%----------------------------------------------------------
% 2. 正文内容
%----------------------------------------------------------

\section{引言}
随着知识图谱技术在金融，风控，情报，个性化推荐等领域中发挥越来越重要的作用。快速地自动化地构建知识图谱，尤其是其子任务实体识别和关系抽取，成为了自然语言处理领域的重要研究课题。
远程监督机制，启发式地将知识库中的三元组与分结构化文本对齐，自动化地标注大量训练数据，不用耗费大量人力物力去手动标注，为构建大规模标注语料库找到了更快的方法，逐渐成为了现在关系抽取领域的一个重要工具。
远程监督机制基于一个最基本的假设：如果两个实体\textbf{e\uline{}1}和\textbf{e\uline{}2}之间存在关系\textbf{r}，那么语料库中所有包含这两个实体的句子，我们都认为可以表述关系\textbf{r}，也会被标注为关系\textbf{r}的训练实例。
例如，在知识库中给定实体对\textbf{姚明}，\textbf{上海}，以及他们之间的关系 \textit{born\uline{}in}，我们可以将语料库中所有同时包含实体\textbf{姚明}， \textbf{上海}的句子标注，认为它们表达了关系\textit{born\uline{}in}。

远程监督尽管明显降低了用于标注的海量人力和时间，但由于其依赖于一个过于绝对的假设，所以总是会构建出一个充满了错误标注噪声的训练数据。
在现实世界中，往往不是每一个句子都会表述我们想要的关系。例如，"姚明，生于中国上海市，祖籍江苏省苏州市吴江区震泽镇，著名篮球运动员"，表述了\textit{born\uline{}in}关系，
而句子“2009年，姚明收购上海男篮，成为上海大鲨鱼篮球俱乐部老板。”并不能体现这个关系。
在真实世界中，远程监督标注的数据总是有着大量类似的噪声数据，有时受限于语料库的质量，关于一对实体的标注数据甚至可能一个正确的实例都没有，这也造成了基于远程监督训练的深度学习模型性能普遍一般。
在单个句子分类能力已经达到了较好水平的情况下，在充满了大量噪声的远程监督数据上，如何训练一个能克服噪声性能良好的分类器，成为了当下研究者关注的重点


为了缓解应对远程监督带来的大量噪声问题，Ridel \cite{bib1} 等人提出来了多实例学习方法。
Ridel将远程监督的假设放宽松，首先我们将标注为一对实体某个关系的所有句子实例称为一个句袋（sentence bag），
Ridel等人认为一个句袋中至少可以有一个句子实例表述了标注的关系，这也称为“至少一个”假设（at least one assumption）。在学习中我们可以只学习一个句袋中最有可能的句子实例，大大降低了噪声数据带来的影响，提升了提取器的性能。
使用了“至少一个”假设学习策略的提取器，最大的瓶颈是在句子特征提取上。

对于长度可变的自然语言文本，如何提取长句子中的隐含依赖关系，是自然语言理解中的重要难题。
早期的学者们常常依赖于外部的自然语言处理工具对于句子及进行词性标注、依存分析等作为句子的特征标注。
这类句子特征生成的最大问题是特征的准确度依赖于这些工具，如果这些工具的准确率不高，也会对后续的分类准确度有着一定的影响。
其次，当句子过长，这类标注工具的准确率会急剧下降。

鉴于深度学习方法在图像领域取得了巨大的成功，自然语言领域也引入了这一强有力的工具，用来自动化地提取自然文本的语义特征。
分段最大池化卷积网络（PCNNs)\cite{bib3}，长短时记忆网络（Long Short Term Memory Network）等都在关系抽取领域的句子特征提取上取得了成功。
然而，CNN与LSTM在提取长序列的语义特征上，依然有其天然的不足。CNN由于卷积核尺寸的限制，无法获取一个长距离的依赖关系。
而LSTM虽然克服了RNN在长距离依赖上的梯度消失问题，却依然不能够处理过于长的序列。

为了能够有效地降低训练数据中的噪声，除了上文中所提到的“至少一个”策略，软注意力机制机制也被广泛使用。
软注意力机制机制在句袋内部，通过计算每一个句子与最终结果的相似度，实现了注意力权重的再分配，有效地利用了句袋内的噪声与非噪声信息。
然而软注意力机制需要串行的计算句子得分和注意力权重，在时间效率上不尽如人意。

为了解决远程监督中句子特征提取和降噪问题，我们提出了层次的注意力机制，基于自注意力机制，能够快速高效的在句子层面提取特征，并且在句袋层面降低噪声。
我们使用了一个基于自注意力机制的句子编码器，能够更好的捕获句子中的任意两个单词之间的长期依赖关系。

\section{相关工作}

\subsection{正文}

\subsubsection{正文字体}

通常情况下，我们不建议在正文中使用\LaTeX的各种字体设置命令，例如：不要直接在正文中使用以下的字体命令：
宋体 \verb|\songti|、黑体 \verb|\heiti|、仿宋 \verb|\fangsong|、楷书 \verb|\kaishu|。
当需要强调某些文字时，建议使用 \verb|\emph{文字}| 命令，也可以直接使用 \verb|\textbf{加粗文字}| 或 \verb|\textit{倾斜文字}| 等。

\subsubsection{脚注}

在正文中插入脚注使用 \verb|\footnote{脚注文本}| 命令\footnote{这里放置脚注的文本内容。}。

\subsubsection{参考文献引用}

在正文中引用参考文献使用序号方式，并根据上下文确定文献引用序号是否采用上标方式。举例：在文献\cite{bib1}中提出一种方法，后续研究对该方法进行了改进\upcite{bib1,bib2}。

\subsection{图形}

本模板提供的文档类 \verb|csoarticle| 本身默认情况下已经包含了 \verb|graphicx| 宏包，因此典型方法是用 \verb|\includegraphics| 命令将图形包含到浮动环境 \verb|figure| 中。图 \ref{fig:sample} 是一个例子。除了 \verb|pdf| 格式外，也支持 \verb|eps|, \verb|jpeg| 等多种格式，具体用法可参看 \verb|graphicx| 宏包的文档。
\begin{figure}
\centering\includegraphics[height=6cm]{figsamp}
\caption{数据曲线图示例}
\label{fig:sample}
\end{figure}

\subsection{表格}

使用浮动环境 \verb|table| 的示例见表\ref{tab:sample}。
\begin{table}
  \caption{表格示例}
  \label{tab:sample}
  \centering
  \begin{tabular}{lcr}%{|l|c|r|}
    \hline
    求解算法                & 系数矩阵的规模    & 执行时间(秒)  \\
    \hline
    Gauss消去法(直接法)     & Mat1903           &  113.27       \\
    Jacobi点迭代            & Mat1784           &  201.36       \\
    \hline
  \end{tabular}
\end{table}

\subsection{数学公式}

本模板提供的文档类 \verb|csoarticle| 本身默认情况下已经包含了 \verb|amsmath| 和 \verb|amsthm| 宏包，因此可以使用这些宏包中提供的一切命令。带编号的数学公式建议使用 \verb|align| 环境。举例如下：一元二次方程
\begin{align}\label{eq:sample}
    a x^2 + b x + c = 0
\end{align}
的两个根为
\begin{align}\label{eq:root}
    x_1 &= \frac{-b + \sqrt{b^2 - 4ac}}{2a} \\
    x_2 &= \frac{-b - \sqrt{b^2 - 4ac}}{2a}
\end{align}
其中，方程\eqref{eq:sample}中的系数$a \not= 0$。

数学类内容中常用的定理类环境也可以直接使用，举例如下（\emph{均为虚拟例子，切勿进行技术性探究}）：
\begin{lemma}\label{lem:levy}
    引理的具体内容。
\end{lemma}
\begin{proof}
    可参看各类数学分析类教材，此处从略。
\end{proof}

\begin{theorem}[牛顿第二定律]\label{thm:newton}
物体的质量$m$、物体所受的力$F$以及物体运动的加速度$a$之间满足
\begin{align}\label{eq:f-eq-ma}
    F = m a
\end{align}
\end{theorem}
\begin{proof}
由引理\ref{lem:levy}及文献\cite{bib1}第15章的定理4可立得。
\end{proof}

请直接查看以上例子的源代码部分。

\subsection{参考文献的格式要求}

文献数量应不低于6篇，综述文章文献数量不低于25篇。

注：文中所引的参考文献, 作者均应认真阅读过, 对文献的作者、题目、发表的刊物、年份、卷期号和起止页码等均应核实无误，并按在正文出现的先后顺序编号。标引的序号两边加“[ ]”，作者不超过3人的姓名都写， 超过3人的第三人后面加“，等（et al）” 。无论中外署名，一律姓（大写）先名后，作者姓名之间以逗号分隔。参考文献一律置于文末。文献正文中所有非英文文献需写出对应的英文译文，具体格式要求如下（例子请参看本模板文后的参考文献）：
\begin{enumerate}
\item\textbf{期刊:}     作者. 论文题目[J]. 刊名，年，卷（期）：起始页码～终止页码.
\item\textbf{专著:}     作者. 书名[M]. 出版地：出版社，出版年.
\item\textbf{译著:}     作者. 书名[M]. 译者. 出版地：出版社，出版年.
\item\textbf{论文集:}   作者. 论文题目[A]. 编者. 文集[C]. 出版地：出版社，出版年. 起始页码～终止页码.
\item\textbf{学位论文:} 作者. 论文题目[D]. 所在城市：保存单位，年份.
\item\textbf{技术标准:} 起草责任者，技术标准代号顺序号—发布年. 技术标准名称[S]. 出版地：出版社，出版年.其中，起草责任者、出版地、出版社、出版年可省。
\item\textbf{专利:}     申请者. 专利名[P]. 国名及专利号，发布日期.
\item\textbf{技术报告:} 作者. 文题[R]. 地名：责任单位，报告代码及编号，年份.
\item\textbf{报纸文章:} 作者. 文题[N]. 报纸名，出版日期（版次）.
\item\textbf{在线文献:} 作者. 文题[OL]. [日期]. http://......
\item\textbf{光盘文献:} 作者. 文题[CD]. 出版地：出版者，出版日期.
\item\textbf{其他文献:} 作者. 文题[Z]. 出版地：出版者，出版日期.
\end{enumerate}

\section{结论}

本文给出了………

\section*{致谢(可选)}

应向对论文有帮助的有关人士或单位表示谢意。


%----------------------------------------------------------
% 3. 参考文献
%----------------------------------------------------------

\begin{thebibliography}{15} % 这里的2是指参考文献总数目，需要根据实际情况进行修改
    \bibitem{bib1} Mike Mintz, Stevens Bills, Rion Snow, et al Distant supervision for relation extraction without labeled data, \textit{Proc. Joint Conf. 47th Annu. Meeting ACL 4th Int. Joint Conf. Natural Lang. Process. (AFNLP) Assoc. Comput. Linguistics}, Aug. 2009, pp. 1003–1011.
    \bibitem{bib2} S. Riedel, L. Yao, and A. McCallum, Modeling relations and their mentions without labeled text, \textit{Proc. Joint Eur. Conf. Mach. Learn. Knowl. Discovery Databases.} Berlin, Germany: Springer, 2010, pp. 148–163.
    \bibitem{bib3} Zeng Daojian, Liu Kang, Chen Yubo, et al, Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks
    \bibitem{bib4} Lin Yankai, Shen Shiqi,Liu Zhiyuan, et al, Neural Relation Extraction with Selective 注意力机制 over Instances
    \bibitem{bib5} Attention Is AL You Need
\end{thebibliography}

\end{document}
